{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to do CV Code\n",
    "\n",
    "1. Install OpenCV on Raaspberry pi \n",
    "2. Install X11 apps to send live feed to laptop  \n",
    "    1. Use Xming X to see live feed\n",
    "\n",
    "3. Install or create Database for tennis balls and cardboard boxes\n",
    "4. Calibrate the camera to get Camera matrices\n",
    "5. Create or modify existing model for Tennis ball detection\n",
    "6. Get a Heatsink for Raspberry Pi \n",
    "\n",
    "\n",
    "\n",
    "<table>\n",
    "<thead>\n",
    "<tr><th>Models</th><th>Estimated FPS on Raspberry Pi 4B</th><th>Notes</th><th>Accuracy (mAP)</th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>Custom Algorithm (e.g., color thresholding + blob detection)</td>\n",
    "<td>10 FPS</td>\n",
    "<td>\n",
    "- Allows the model to be tailored to the robot's conditions<br>\n",
    "- More time-consuming to create model from scratch<br>\n",
    "- Can be very fast but may struggle with complex scenes or varying lighting conditions\n",
    "</td>\n",
    "<td>Varies (typically lower than ML models)</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>MobileNet-SSD v2</td>\n",
    "<td>1-3 FPS</td>\n",
    "<td>\n",
    "- Good balance of speed and accuracy<br>\n",
    "- Designed for mobile and embedded devices<br>\n",
    "- Widely used and well-documented\n",
    "</td>\n",
    "<td>22.1% mAP (COCO dataset)</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>YOLOv5-nano</td>\n",
    "<td>0.5-2 FPS</td>\n",
    "<td>\n",
    "- Very small model size (~1MB)<br>\n",
    "- Good for detecting small objects<br>\n",
    "- May require careful optimization for Raspberry Pi\n",
    "</td>\n",
    "<td>25.4% mAP (COCO dataset)</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>EfficientDet-Lite0</td>\n",
    "<td>0.5-1.5 FPS</td>\n",
    "<td>\n",
    "- Balanced efficiency-accuracy trade-off<br>\n",
    "- Part of the EfficientDet family, known for scalability<br>\n",
    "- Good documentation and TensorFlow Lite support\n",
    "</td>\n",
    "<td>27.5% mAP (COCO dataset)</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>TinyYOLOv3</td>\n",
    "<td>1-3 FPS</td>\n",
    "<td>\n",
    "- Designed for speed on embedded devices<br>\n",
    "- Smaller and faster than full YOLOv3<br>\n",
    "- May miss small objects more often than larger models\n",
    "</td>\n",
    "<td>33.1% mAP (COCO dataset)</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>MobileNetV2 + SSDLite</td>\n",
    "<td>1-2 FPS</td>\n",
    "<td>\n",
    "- Optimized version of MobileNet-SSD<br>\n",
    "- Very memory-efficient<br>\n",
    "- Good for resource-constrained devices\n",
    "</td>\n",
    "<td>22% mAP (COCO dataset)</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "predefined models may be faster if we limit what its looking for, we could use this as a safety meaasure, incase custom model doesnt work\n",
    "-   I.e. Work on developing a pre developed model such as MobileNet or YOLO through TensorLite, then work on Custom Model \n",
    "- USe of Roboflow to create Datasets, or use Predefined datasets, limiting what its trained on "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Algorithm\n",
    "#### Colour Based Detection \n",
    "1. Convert image to HSV colourspace\n",
    "2. Define colour range of tennis balls \n",
    "3. Create binary mask using the colour range of tennis ball\n",
    "4. Apply morphological operations to clean the mask \n",
    "5. Filter contours based on area and circularity\n",
    "\n",
    "#### Edge Detection \n",
    "1. Convert images to greyscale\n",
    "2. Apply Gaussian Blur to reduce noise\n",
    "3. Use Canny Edge detection \n",
    "4. Apply Hough Circle transform \n",
    "5. Filter circles based on size\n",
    "\n",
    "#### Combination of methods \n",
    "1. Use colour thereshold to create a region of interest \n",
    "2. Apply Hough Transformation only on ROI \n",
    "3. Verify using colour information \n",
    "\n",
    "#### Ball Tracking (Kalman Filters)\n",
    "1. Initialise Kalman Filter for each ball detected \n",
    "2. Predict new positions in each frame \n",
    "3. Update predictions with new detections\n",
    "\n",
    "##### Tips to make it faster\n",
    "- Implimenting multi-threadings to parallelize detection and robot control \n",
    "-       reducing image resolution to improve processing speed\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Installing Dependencies for google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add all dependencies here for google colab and training \n",
    "\n",
    "# the following section of code needs to be un when operating on google colab\n",
    "!pip uninstall Cython -y\n",
    "!git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copying setup files into model/research folder\n",
    "%%bash \n",
    "cd models/research\n",
    "protoc object_detection/protos/*.proto --python_out=.\n",
    "#cp object_detection/packages/tf2/setup.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify setup.py file to install the tf-models-official repository targeted at TF v2.8.0\n",
    "import re\n",
    "with open('/content/models/research/object_detection/packages/tf2/setup.py') as f:\n",
    "    s = f.read()\n",
    "\n",
    "with open('/content/models/research/setup.py', 'w') as f:\n",
    "    # Set fine_tune_checkpoint path\n",
    "    s = re.sub('tf-models-official>=2.5.1',\n",
    "               'tf-models-official==2.8.0', s)\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Object Detection API (NOTE: This block takes about 10 minutes to finish executing)\n",
    "\n",
    "# Need to do a temporary fix with PyYAML because Colab isn't able to install PyYAML v5.4.1\n",
    "!pip install pyyaml==5.3\n",
    "!pip install /content/models/research/\n",
    "\n",
    "# Need to downgrade to TF v2.8.0 due to Colab compatibility bug with TF v2.10 (as of 10/03/22)\n",
    "!pip install tensorflow==2.8.0\n",
    "\n",
    "# Install CUDA version 11.0 (to maintain compatibility with TF v2.8.0)\n",
    "!pip install tensorflow_io==0.23.1\n",
    "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\n",
    "!mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\n",
    "!wget http://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\n",
    "!dpkg -i cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\n",
    "!apt-key add /var/cuda-repo-ubuntu1804-11-0-local/7fa2af80.pub\n",
    "!apt-get update && sudo apt-get install cuda-toolkit-11-0\n",
    "!export LD_LIBRARY_PATH=/usr/local/cuda-11.0/lib64:$LD_LIBRARY_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifying the model by running Model Builder\n",
    "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dataset manipulation, getting it ready for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below code for Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive \n",
    "drive.mount('/content/gdrive')\n",
    "!cp /content/gdrive/MyDrive/path/to/images.zip /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/util_scripts/create_csv.py\n",
    "! wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/util_scripts/create_tfrecord.py\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.core.example import example_pb2\n",
    "!python3 create_csv.py\n",
    "!python3 create_tfrecord.py --csv_input=images/train_labels.csv --labelmap=labelmap.txt --image_dir=images/train --output_path=train.tfrecord\n",
    "!python3 create_tfrecord.py --csv_input=images/validation_labels.csv --labelmap=labelmap.txt --image_dir=images/validation --output_path=val.tfrecord\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Setup Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the chosen_model variable to deploy different models available in the TF2 object detection zoo\n",
    "chosen_model = 'ssd-mobilenet-v2-fpnlite-320'\n",
    "\n",
    "MODELS_CONFIG = {\n",
    "    'ssd-mobilenet-v2': {\n",
    "        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n",
    "        'base_pipeline_file': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz',\n",
    "    },\n",
    "    'efficientdet-d0': {\n",
    "        'model_name': 'efficientdet_d0_coco17_tpu-32',\n",
    "        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n",
    "    },\n",
    "    'ssd-mobilenet-v2-fpnlite-320': {\n",
    "        'model_name': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8',\n",
    "        'base_pipeline_file': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz',\n",
    "    },\n",
    "    # The centernet model isn't working as of 9/10/22\n",
    "    #'centernet-mobilenet-v2': {\n",
    "    #    'model_name': 'centernet_mobilenetv2fpn_512x512_coco17_od',\n",
    "    #    'base_pipeline_file': 'pipeline.config',\n",
    "    #    'pretrained_checkpoint': 'centernet_mobilenetv2fpn_512x512_coco17_od.tar.gz',\n",
    "    #}\n",
    "}\n",
    "\n",
    "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
    "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
    "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir /content/model/my_model\n",
    "%cd /content/model/my_model\n",
    "\n",
    "#downloading the pretrained model\n",
    "import tarfile\n",
    "download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n",
    "!wget {download_tar}\n",
    "tar = tarfile.open(pretrained_checkpoint)\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "\n",
    "# Download training configuration file for model\n",
    "download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n",
    "!wget {download_config}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up training params for the model\n",
    "num_steps = 40000\n",
    "if chosen_model == 'efficientdet-d0':\n",
    "    batch_size = 4\n",
    "else:\n",
    "    batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_fname = './content/models/mymodel/' + base_pipeline_file\n",
    "fine_tune_checkpoint = './content/models/mymodel/' + model_name + '/checkpoint/ckpt-0'\n",
    "\n",
    "def get_num_classes(pbxt_fname):\n",
    "    from object_detection.utils import label_map_util\n",
    "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
    "    categories = label_map_util.convert_label_map_to_categories(\n",
    "        label_map, max_num_classes=90, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "    return len(category_index.keys())\n",
    "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
    "print('Total classes:', num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom configuration file by writing the dataset, model checkpoint, and training parameters into the base pipeline file\n",
    "import re\n",
    "\n",
    "%cd /content/models/mymodel\n",
    "print('writing custom configuration file')\n",
    "\n",
    "with open(pipeline_fname) as f:\n",
    "    s = f.read()\n",
    "with open('pipeline_file.config', 'w') as f:\n",
    "\n",
    "    # Set fine_tune_checkpoint path\n",
    "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
    "\n",
    "    # Set tfrecord files for train and test datasets\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(val_record_fname), s)\n",
    "\n",
    "    # Set label_map_path\n",
    "    s = re.sub(\n",
    "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
    "\n",
    "    # Set batch_size\n",
    "    s = re.sub('batch_size: [0-9]+',\n",
    "               'batch_size: {}'.format(batch_size), s)\n",
    "\n",
    "    # Set training steps, num_steps\n",
    "    s = re.sub('num_steps: [0-9]+',\n",
    "               'num_steps: {}'.format(num_steps), s)\n",
    "\n",
    "    # Set number of classes num_classes\n",
    "    s = re.sub('num_classes: [0-9]+',\n",
    "               'num_classes: {}'.format(num_classes), s)\n",
    "\n",
    "    # Change fine-tune checkpoint type from \"classification\" to \"detection\"\n",
    "    s = re.sub(\n",
    "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
    "\n",
    "    # If using ssd-mobilenet-v2, reduce learning rate (because it's too high in the default config file)\n",
    "    if chosen_model == 'ssd-mobilenet-v2':\n",
    "      s = re.sub('learning_rate_base: .8',\n",
    "                 'learning_rate_base: .08', s)\n",
    "\n",
    "      s = re.sub('warmup_learning_rate: 0.13333',\n",
    "                 'warmup_learning_rate: .026666', s)\n",
    "\n",
    "    # If using efficientdet-d0, use fixed_shape_resizer instead of keep_aspect_ratio_resizer (because it isn't supported by TFLite)\n",
    "    if chosen_model == 'efficientdet-d0':\n",
    "      s = re.sub('keep_aspect_ratio_resizer', 'fixed_shape_resizer', s)\n",
    "      s = re.sub('pad_to_max_dimension: true', '', s)\n",
    "      s = re.sub('min_dimension', 'height', s)\n",
    "      s = re.sub('max_dimension', 'width', s)\n",
    "\n",
    "    f.write(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the custom config file and the directory to store training checkpoints in\n",
    "pipeline_file = '/content/models/mymodel/pipeline_file.config'\n",
    "model_dir = '/content/training/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir '/content/training/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training!\n",
    "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
    "    --pipeline_config_path={pipeline_file} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --alsologtostderr \\\n",
    "    --num_train_steps={num_steps} \\\n",
    "    --sample_1_of_n_eval_examples=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Converting model o TensorFlow Lite ans saving it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a directory to store the trained TFLite model\n",
    "!mkdir /content/custom_model_lite\n",
    "output_directory = '/content/custom_model_lite'\n",
    "\n",
    "# Path to training directory (the conversion script automatically chooses the highest checkpoint file)\n",
    "last_model_path = '/content/training'\n",
    "\n",
    "!python /content/models/research/object_detection/export_tflite_graph_tf2.py \\\n",
    "    --trained_checkpoint_dir {last_model_path} \\\n",
    "    --output_directory {output_directory} \\\n",
    "    --pipeline_config_path {pipeline_file}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert exported graph file into TFLite model file\n",
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('/content/custom_model_lite/saved_model')\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('/content/custom_model_lite/detect.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Deployment of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model and use it to detect in this bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Quantasize the model (maybe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
