{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to do CV Code\n",
    "\n",
    "1. Install OpenCV on Raaspberry pi \n",
    "2. Install X11 apps to send live feed to laptop  \n",
    "    1. Use Xming X to see live feed\n",
    "\n",
    "3. Install or create Database for tennis balls and cardboard boxes\n",
    "4. Calibrate the camera to get Camera matrices\n",
    "5. Create or modify existing model for Tennis ball detection\n",
    "6. Get a Heatsink for Raspberry Pi \n",
    "\n",
    "\n",
    "\n",
    "<table>\n",
    "<thead>\n",
    "<tr><th>Models</th><th>Estimated FPS on Raspberry Pi 4B</th><th>Notes</th><th>Accuracy (mAP)</th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>Custom Algorithm (e.g., color thresholding + blob detection)</td>\n",
    "<td>10 FPS</td>\n",
    "<td>\n",
    "- Allows the model to be tailored to the robot's conditions<br>\n",
    "- More time-consuming to create model from scratch<br>\n",
    "- Can be very fast but may struggle with complex scenes or varying lighting conditions\n",
    "</td>\n",
    "<td>Varies (typically lower than ML models)</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>MobileNet-SSD v2</td>\n",
    "<td>1-3 FPS</td>\n",
    "<td>\n",
    "- Good balance of speed and accuracy<br>\n",
    "- Designed for mobile and embedded devices<br>\n",
    "- Widely used and well-documented\n",
    "</td>\n",
    "<td>22.1% mAP (COCO dataset)</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>YOLOv5-nano</td>\n",
    "<td>0.5-2 FPS</td>\n",
    "<td>\n",
    "- Very small model size (~1MB)<br>\n",
    "- Good for detecting small objects<br>\n",
    "- May require careful optimization for Raspberry Pi\n",
    "</td>\n",
    "<td>25.4% mAP (COCO dataset)</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>EfficientDet-Lite0</td>\n",
    "<td>0.5-1.5 FPS</td>\n",
    "<td>\n",
    "- Balanced efficiency-accuracy trade-off<br>\n",
    "- Part of the EfficientDet family, known for scalability<br>\n",
    "- Good documentation and TensorFlow Lite support\n",
    "</td>\n",
    "<td>27.5% mAP (COCO dataset)</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>TinyYOLOv3</td>\n",
    "<td>1-3 FPS</td>\n",
    "<td>\n",
    "- Designed for speed on embedded devices<br>\n",
    "- Smaller and faster than full YOLOv3<br>\n",
    "- May miss small objects more often than larger models\n",
    "</td>\n",
    "<td>33.1% mAP (COCO dataset)</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>MobileNetV2 + SSDLite</td>\n",
    "<td>1-2 FPS</td>\n",
    "<td>\n",
    "- Optimized version of MobileNet-SSD<br>\n",
    "- Very memory-efficient<br>\n",
    "- Good for resource-constrained devices\n",
    "</td>\n",
    "<td>22% mAP (COCO dataset)</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "predefined models may be faster if we limit what its looking for, we could use this as a safety meaasure, incase custom model doesnt work\n",
    "-   I.e. Work on developing a pre developed model such as MobileNet or YOLO through TensorLite, then work on Custom Model \n",
    "- USe of Roboflow to create Datasets, or use Predefined datasets, limiting what its trained on "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Algorithm\n",
    "#### Colour Based Detection \n",
    "1. Convert image to HSV colourspace\n",
    "2. Define colour range of tennis balls \n",
    "3. Create binary mask using the colour range of tennis ball\n",
    "4. Apply morphological operations to clean the mask \n",
    "5. Filter contours based on area and circularity\n",
    "\n",
    "#### Edge Detection \n",
    "1. Convert images to greyscale\n",
    "2. Apply Gaussian Blur to reduce noise\n",
    "3. Use Canny Edge detection \n",
    "4. Apply Hough Circle transform \n",
    "5. Filter circles based on size\n",
    "\n",
    "#### Combination of methods \n",
    "1. Use colour thereshold to create a region of interest \n",
    "2. Apply Hough Transformation only on ROI \n",
    "3. Verify using colour information \n",
    "\n",
    "#### Ball Tracking (Kalman Filters)\n",
    "1. Initialise Kalman Filter for each ball detected \n",
    "2. Predict new positions in each frame \n",
    "3. Update predictions with new detections\n",
    "\n",
    "##### Tips to make it faster\n",
    "- Implimenting multi-threadings to parallelize detection and robot control \n",
    "-       reducing image resolution to improve processing speed\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add all dependencies here for google colab and training \n",
    "\n",
    "# the following section of code needs to be un when operating on google colab\n",
    "!pip uninstall Cython -y\n",
    "!git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copying setup files into model/research folder\n",
    "%%bash \n",
    "cd models/research\n",
    "protoc object_detection/protos/*.proto --python_out=.\n",
    "#cp object_detection/packages/tf2/setup.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify setup.py file to install the tf-models-official repository targeted at TF v2.8.0\n",
    "import re\n",
    "with open('/content/models/research/object_detection/packages/tf2/setup.py') as f:\n",
    "    s = f.read()\n",
    "\n",
    "with open('/content/models/research/setup.py', 'w') as f:\n",
    "    # Set fine_tune_checkpoint path\n",
    "    s = re.sub('tf-models-official>=2.5.1',\n",
    "               'tf-models-official==2.8.0', s)\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Object Detection API (NOTE: This block takes about 10 minutes to finish executing)\n",
    "\n",
    "# Need to do a temporary fix with PyYAML because Colab isn't able to install PyYAML v5.4.1\n",
    "!pip install pyyaml==5.3\n",
    "!pip install /content/models/research/\n",
    "\n",
    "# Need to downgrade to TF v2.8.0 due to Colab compatibility bug with TF v2.10 (as of 10/03/22)\n",
    "!pip install tensorflow==2.8.0\n",
    "\n",
    "# Install CUDA version 11.0 (to maintain compatibility with TF v2.8.0)\n",
    "!pip install tensorflow_io==0.23.1\n",
    "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\n",
    "!mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\n",
    "!wget http://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\n",
    "!dpkg -i cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\n",
    "!apt-key add /var/cuda-repo-ubuntu1804-11-0-local/7fa2af80.pub\n",
    "!apt-get update && sudo apt-get install cuda-toolkit-11-0\n",
    "!export LD_LIBRARY_PATH=/usr/local/cuda-11.0/lib64:$LD_LIBRARY_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifying the model by running Model Builder\n",
    "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dataset manipulation, getting it ready for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add code for dataset manipulation \n",
    "\n",
    "# loading dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Setup Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the chosen_model variable to deploy different models available in the TF2 object detection zoo\n",
    "chosen_model = 'ssd-mobilenet-v2-fpnlite-320'\n",
    "\n",
    "MODELS_CONFIG = {\n",
    "    'ssd-mobilenet-v2': {\n",
    "        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n",
    "        'base_pipeline_file': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz',\n",
    "    },\n",
    "    'efficientdet-d0': {\n",
    "        'model_name': 'efficientdet_d0_coco17_tpu-32',\n",
    "        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n",
    "    },\n",
    "    'ssd-mobilenet-v2-fpnlite-320': {\n",
    "        'model_name': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8',\n",
    "        'base_pipeline_file': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz',\n",
    "    },\n",
    "    # The centernet model isn't working as of 9/10/22\n",
    "    #'centernet-mobilenet-v2': {\n",
    "    #    'model_name': 'centernet_mobilenetv2fpn_512x512_coco17_od',\n",
    "    #    'base_pipeline_file': 'pipeline.config',\n",
    "    #    'pretrained_checkpoint': 'centernet_mobilenetv2fpn_512x512_coco17_od.tar.gz',\n",
    "    #}\n",
    "}\n",
    "\n",
    "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
    "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
    "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 3] The system cannot find the path specified: '/content/model/my_model'\n",
      "g:\\Other computers\\Surface\\Uni Work\\2024\\Sem 2\\ECE4191\\github\\ECE4191_G43_S2_2024\\CV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The syntax of the command is incorrect.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m download_tar \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://download.tensorflow.org/models/object_detection/tf2/20200711/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m pretrained_checkpoint\n\u001b[0;32m      7\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwget \u001b[39m\u001b[38;5;132;01m{download_tar}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m tar \u001b[38;5;241m=\u001b[39m \u001b[43mtarfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_checkpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m tar\u001b[38;5;241m.\u001b[39mextractall()\n\u001b[0;32m     10\u001b[0m tar\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\parth\\miniconda3\\envs\\AI_ML\\Lib\\tarfile.py:1802\u001b[0m, in \u001b[0;36mTarFile.open\u001b[1;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[0;32m   1800\u001b[0m     saved_pos \u001b[38;5;241m=\u001b[39m fileobj\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m   1801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ReadError, CompressionError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1804\u001b[0m     error_msgs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m- method \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcomptype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\parth\\miniconda3\\envs\\AI_ML\\Lib\\tarfile.py:1870\u001b[0m, in \u001b[0;36mTarFile.gzopen\u001b[1;34m(cls, name, mode, fileobj, compresslevel, **kwargs)\u001b[0m\n\u001b[0;32m   1867\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CompressionError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip module is not available\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1870\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[43mGzipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompresslevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1871\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1872\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\parth\\miniconda3\\envs\\AI_ML\\Lib\\gzip.py:192\u001b[0m, in \u001b[0;36mGzipFile.__init__\u001b[1;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[0;32m    190\u001b[0m     mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmyfileobj \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    194\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fileobj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'"
     ]
    }
   ],
   "source": [
    "%mkdir /content/model/my_model\n",
    "%cd /content/model/my_model\n",
    "\n",
    "#downloading the pretrained model\n",
    "import tarfile\n",
    "download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n",
    "!wget {download_tar}\n",
    "tar = tarfile.open(pretrained_checkpoint)\n",
    "tar.extractall()\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Converting model o TensorFlow Lite ans saving it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Deployment of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model and use it to detect in this bit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Quantasize the model (maybe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
